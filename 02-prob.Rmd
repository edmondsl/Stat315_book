
```{r,echo=FALSE,message=FALSE,warning=FALSE}
library(formatR)
library(tidyverse)
library(kableExtra)

# Set so that long lines in R will be wrapped:
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=80), tidy=FALSE)
knitr::opts_chunk$set(cache=TRUE,warning=F)
knitr::opts_chunk$set(out.height='40%',fig.align = "center")
add.space = 0

# kable table global setup
kt = function(data) {
  kable(data, align = "c", escape = FALSE) %>%
    kable_styling(bootstrap_options = c("striped"),
                  latex_options = c("hold_position"))
}
```

# Probability

In this chapter, weâ€™ll delve into Probability, the branch of mathematics that deals with the study of randomness and uncertainty, helping us understand and quantify the likelihood of different outcomes.

## Sample Space and Events

:::{.definition}
An ***experiment*** is any activity or process whose outcome is subject to uncertainty.
:::

:::{.definition}
The ***sample space*** of an experiment, denoted by $\Omega$ or $\mathcal{S}$, is the set of all possible outcomes of that experiment.
:::

:::{.definition}
An ***event*** is any collection (subset) of outcomes contained in the sample space $\Omega$.
:::

:::{.example}
For the following examples, define the sample space and give an example of an event. Code for running the experiment in R is given.
:::

**Experiment 1:** Roll a fair six-sided die.

```{r}
# roll one fair six-sided die in R
sample(x=1:6,size=1)
```

**Experiment 2:** Roll two fair six-sided dice.

```{r}
# roll two fair six-sided dice in R
sample(x=1:6,size=2)
```

**Experiment 3:** Randomly select a real number in the closed interval from 0 to 1.

```{r}
# generate one random number between 0 and 1
runif(n=1)
```

\newpage


## Set Theory

**Note:** For the following examples, suppose a fair six-sided die is rolled, so $\Omega=\{1,2,3,4,5,6\}$.

Define the following events: $A = \text{roll an even} = \{2,4,6\}$, $B=\text{roll a 3 or higher} =\{3,4,5,6\}$, $C=\text{roll a prime number}=\{2,3,5\}$.

:::{.definition}
A ***complement*** of an event A, denoted by $A^c$ or A', is the set of all outcomes in $\Omega$ that are not contained in A.
:::

**Illustration**

```{r, echo=F, out.height="10%",fig.align="left"}
library(ggplot2)

# Define the size of the box and the circle
box_size = 10
circle_radius = 3

# Create a data frame for the circle
circle = data.frame(
  x = circle_radius * cos(seq(0, 2 * pi, length.out = 100)) + box_size / 2,
  y = circle_radius * sin(seq(0, 2 * pi, length.out = 100)) + box_size / 2
)

# Create the plot
venn1 = ggplot() +
  # Draw the box
  geom_rect(aes(xmin = 0, xmax = box_size, ymin = 0, ymax = box_size),
            fill = "white", color = "black") +
  # Draw the circle
  geom_polygon(data = circle, aes(x = x, y = y), fill = "white", color = "black") +
  # Set the aspect ratio to 1:1
  coord_fixed() +
  # Remove axes and labels
  theme_void() +
  theme(plot.title = element_text(hjust = 0.5))
venn1
```


:::{.definition}
The ***union*** of two events A and B, denoted by $A \cup B$ and read "A or B", is the event consisting of all outcomes that are either in A or B or in both.
:::

**Illustration**

```{r, echo=F, out.height="10%",fig.align="left"}
# Define the size of the box and the circle
box_size = 10
circle_radius = 3

# Adjust the centers for the circles to create a proper overlap
circle1 = data.frame(
  x = circle_radius * cos(seq(0, 2 * pi, length.out = 100)) + (box_size / 2) - (circle_radius / 2),
  y = circle_radius * sin(seq(0, 2 * pi, length.out = 100)) + box_size / 2
)

circle2 = data.frame(
  x = circle_radius * cos(seq(0, 2 * pi, length.out = 100)) + (box_size / 2) + (circle_radius / 2),
  y = circle_radius * sin(seq(0, 2 * pi, length.out = 100)) + box_size / 2
)

# Create the plot
venn2 = ggplot() +
  # Draw the box
  geom_rect(aes(xmin = 0, xmax = box_size, ymin = 0, ymax = box_size),
            fill = "white", color = "black") +
  # Draw the first circle with some transparency
  geom_polygon(data = circle1, aes(x = x, y = y), fill = "white", color = "black", alpha = 0.5) +
  # Draw the second circle with some transparency
  geom_polygon(data = circle2, aes(x = x, y = y), fill = "white", color = "black", alpha = 0.5) +
  # Set the aspect ratio to 1:1
  coord_fixed() +
  # Remove axes and labels
  theme_void() +
  theme(plot.title = element_text(hjust = 0.5))
venn2
```

```{r,echo=F}
library(ggplot2)

# Define the size of the box and the circle
box_size = 10
circle_radius = 3

# Adjust the centers for the circles to create a proper overlap
circle1 = data.frame(
  x = circle_radius * cos(seq(0, 2 * pi, length.out = 100)) + (box_size / 3),
  y = circle_radius * sin(seq(0, 2 * pi, length.out = 100)) + (box_size / 2) + 1  # Moved up more
)

circle2 = data.frame(
  x = circle_radius * cos(seq(0, 2 * pi, length.out = 100)) + 2 * (box_size / 3),
  y = circle_radius * sin(seq(0, 2 * pi, length.out = 100)) + (box_size / 2) + 1  # Moved up more
)

circle3 = data.frame(
  x = circle_radius * cos(seq(0, 2 * pi, length.out = 100)) + (box_size / 2),
  y = circle_radius * sin(seq(0, 2 * pi, length.out = 100)) + (box_size / 3)
)

# Create the plot
venn3 = ggplot() +
  # Draw the box
  geom_rect(aes(xmin = 0, xmax = box_size, ymin = 0, ymax = box_size),
            fill = "white", color = "black") +
  # Draw the first circle with some transparency
  geom_polygon(data = circle1, aes(x = x, y = y), fill = "white", color = "black", alpha = 0.5) +
  # Draw the second circle with some transparency
  geom_polygon(data = circle2, aes(x = x, y = y), fill = "white", color = "black", alpha = 0.5) +
  # Draw the third circle with some transparency
  geom_polygon(data = circle3, aes(x = x, y = y), fill = "white", color = "black", alpha = 0.5) +
  # Set the aspect ratio to 1:1
  coord_fixed() +
  # Remove axes and labels
  theme_void() +
  theme(plot.title = element_text(hjust = 0.5))
```


:::{.definition}
The ***intersection*** of two events A and B, denoted by $A \cap B$ and read "A and B", is the event consisting of all outcomes that are in both A and B.
:::

**Illustration**


```{r, echo=F, out.height="10%",fig.align="left"}
venn2
```

:::{.definition}
The ***set difference*** of two events A and B, denoted by A\textbackslash B and read "difference of A and B", is the event consisting of all outcomes that are in A but not in B.
:::

**Illustration**


```{r, echo=F, out.height="10%",fig.align="left"}
venn2
```

:::{.definition}
The ***null or empty set*** is the set of no events (or elements), denoted $\emptyset$.
:::

:::{.definition}
When $A \cap B = \emptyset$, A and B are said to be ***mutually exclusive (or disjoint)*** events.
:::

\newpage

:::{.example}
Suppose a fair six-sided die is rolled, so $\Omega=\{1,2,3,4,5,6\}$.

Define the following events: $A = \text{roll an even} = \{2,4,6\}$, $B=\text{roll a 3 or higher} =\{3,4,5,6\}$, $C=\text{roll a prime number}=\{2,3,5\}$.

Determine the following sets and fill in the Venn diagrams representing these sets.
:::

:::{.example}
Draw and determine $A \cup B^c$.
:::

\vfill

```{r, echo=F, out.height="15%",fig.align="left"}
grid.arrange(venn2,venn2,venn2,ncol=3)
```

:::{.example}
Draw and determine $A \cap B \cap C^C$.
:::

\vfill

```{r, echo=F, out.height="15%",fig.align="left"}
grid.arrange(venn3,venn3,venn3,ncol=3)
```

:::{.example}
Draw and determine $[A \cup B] \cap C$.
:::

\vfill

```{r, echo=F, out.height="15%",fig.align="left"}
grid.arrange(venn3,venn3,venn3,ncol=3)
```

:::{.example}
Draw and determine $A \cap B \cap C$.
:::

\vfill

```{r, echo=F, out.height="15%",fig.align="left"}
grid.arrange(venn3,venn3,venn3,ncol=3)
```



\newpage

## Axioms and Rules of Probability

:::{.definition}
The probability of an event, $A$, is denoted by $P(A)$ and represents the likelihood or chance that the event $A$ will occur. Note that $0 \leq P(A) \leq 1$.
:::

**Axioms of Probability**

The axioms of probability were introduced by the mathematician Andrey Kolmogorov in 1933. These axioms form the foundation of probability theory, providing a rigorous, axiomatic framework for quantifying uncertainty. In mathematics, an axiomatic approach means that all rules and theorems are built from a set of fundamental principles, or axioms. 

**Axiom 1:** For any event A, $P(A) \ge 0$

**Axiom 2:** $P(\Omega) = 1$

**Axiom 3:** If $A_1, A_2, A_3, \dots$ is an infinite collection of disjoint events, then
\[P \big( \cup_{i=1}^{\infty} A_i \big) = P(A_1 \cup A_2 \cup A_3 \cup \dots) = \sum_{i=1}^{\infty} P(A_i)\]




**Probability Rules**

The following can be derived from the Axioms of Probability.

\vfill

1. $P(\emptyset) = 0$ 

\vfill

2. For any event A, $P(A) + P(A^c)$ = 1

\vfill

3. $P(A^c) = 1 - P(A)$ 

\vfill

4. For any event A, $0 \le P(A) \le 1$

\vfill

5. For any two events A and B,
$P(A \cup B) = P(A) + P(B) - P(A \cap B)$

\vfill

6. For any three events A, B, and C,

$P(A \cup B \cup C) = P(A) + P(B) + P(C) - P(A \cap B) - P(A \cap C) - P(B \cap C) + P(A \cap B \cap C)$.

\vfill

7. $\left[A \cup B\right]^C = A^C \cap B^C$

\vfill

8. $\left[A \cap B\right]^C = A^C \cup B^C$

\newpage

:::{.example}
Suppose our class has the following breakdown:

70\% Math students \
20\% seniors \
30\% Born in Denver \
10\% Math students and seniors \
15\% Math students and born in Denver \
10\% Seniors and Born in Denver \
5\% Math students, seniors, and born in Denver \

Define events as follows: A = Math student, B = senior, C = Born in Denver.

Suppose a random student from the class is selected. Calculate the following probabilities.
:::

(a) $P(A \cup B)$
\vfill

(b) $P(C \backslash B)$ 
\vfill

(c) $P([A \cap C]^c)$ 
\vfill

$P(A \cup B \cup C)$
\vfill

\newpage

## Counting Techniques

**Equally Likely Outcomes**

If $\Omega = \lbrace x_1, x_2, ... x_N \rbrace$ and all outcomes are equally likely, then $P(A) = |A| / N$, where $|A|$ is the number of outcomes contained in the event A.

:::{.example}
You roll a fair six-sided die. Calculate $P(even)$.
:::

\vfill

:::{.theorem}
(Product Rule for Ordered Pairs) If the first element of an ordered pair can be selected in $n_1$ ways and for each of the these $n_1$ ways the second element of the pair can be selected in $n_2$ ways, then the number of pairs is $n_1 \cdot n_2$.
:::

:::{.example}
You flip three fair coins. Calculate the probability that all are heads or all are tails.
:::

\vfill

:::{.theorem}
(Generalized Product Rule) Suppose a set consists of k elements (k-tuples) and that there are $n_1$ possible choices for the first element, $n_2$ possible choices for the second element, ... , and $n_k$ possible choices for the $k^{th}$ element, then there are $n_1 \cdot n_2 \cdot \cdots n_k$ possible k-tuples.
:::

:::{.example}
How many license plates can be chosen if the first three symbols are letters and the last three symbols are numbers?
:::
\vfill

\newpage

The factorial function, $n!$, is important in counting methods and probability. It is the product of all positive integers less than or equal to $n$, that is, $n! =n \cdot (n-1) \cdot (n-2) \cdot \ldots \cdot 2 \cdot 1 \text{ for } n \in \mathbb{Z}^+$.

**Note:** $0! = 1$

:::{.definition}
An ordered subset is called a ***permutation***. The number of permutations of size $k$ that can be formed from the $n$ elements in a set will be denoted by $P_{n,k}$.

$\boxed{P_{n,k} = \frac{n!}{(n-k)!}}$
:::

:::{.definition}
An unordered subset is called a ***combination***. The number of combinations of size $k$ that can be formed from the $n$ elements in a set will be denoted by $\binom{n}{k}$ or $C_{n,k}$.

$\boxed{\binom{n}{k} = C_{n,k} = \frac{n!}{k! \cdot (n-k)!}}$
:::

:::{.example}
Suppose there are five competitors in an Olympic competition. A gold, a silver, and a bronze medal are awarded for the top three competitors. Are combinations or permutations more appropriate for this situation? How many possible ways can these three awards be given out?
:::

\vfill

:::{.example}
Suppose there are five competitors in an Olympic competition and only three can advance to the final competition. Are combinations or permutations more appropriate for this situation? How many possible ways can you choose three people from a group of five?
:::

\vfill

\newpage

:::{.example}
Powerball is an American lottery game where participants pay \$2 for a chance of winning the grand prize, typically hundreds of millions of dollars. Participants choose five numbers between 1 and 69 and one additional number between 1 and 26. If they choose all the numbers correctly, they win the grand prize. What is the probability of matching all six numbers?
:::

\vfill

:::{.example}
Suppose you are dealt three cards from a standard 52-card playing deck. What is the probability that you get a heart, a diamond, and a club in that order? What if order doesn't matter?
:::

\vfill

\newpage

## Conditional Probability

Conditional probability is the likelihood of an event occurring given that another event has already occurred. It refines our understanding of probability by taking into account additional information that might affect the outcome. Understanding conditional probabilities is crucial in many areas of statistics and decision-making, as it allows us to update our predictions and assessments based on new evidence.

:::{.definition}
For any two events A and B with $P(B)>0$, the \underline{conditional probability of A given B} is defined by:
\[P(A|B) = \frac{P(A \cap B)}{P(B)}\]
:::

\vfill

:::{.example}
The following is a contingency table from a survey on congressional approval.
:::

```{r,echo=F}
library(knitr)

# Create the data frame
data = data.frame(
  `Political Affiliation` = c("Republican", "Democrat", "Independent", "Total"),
  `Approves of Congress` = c(100, 20, 40, 160),
  `Disapproves of Congress` = c(20, 80, 40, 140),
  `Total` = c(120, 100, 80, 300)
)

# Render the table using kable
kable(data, format = "markdown", align = "c", col.names = c("Political Affiliation", "Approves of Congress", "Disapproves of Congress", "Total"))
```

(a) What is the probability that a randomly selected individual from the survey approves of Congress?

\vfill

(b) What is the probability that a randomly selected individual approves of Congress given that they are Democrat?

\vfill

(c) Given that the randomly selected person approves of the Congress, what is the probability that they are Republican?

\vfill

\newpage


:::{.theorem}
Multiplication Rule: $P(A \cap B) = P(A|B) \cdot P(B)$
:::

:::{.example}
Suppose that people with a genetic variation have a 50\% chance of getting a rare disease. The probability of having the genetic variation is 1\%. What is the probability that a randomly chosen person has the genetic variation and also has the disease?
:::

\vfill

:::{.theorem}
Law of Total Probability: Let $A_1, A_2, \ldots, A_k$ be mutually exclusive and exhaustive events (i.e., the events form a partition). Then for any event B,
\[P(B) = P(B|A_1) \cdot P(A_1) + P(B|A_2) \cdot P(A_2) + \ldots + P(B|A_k) \cdot P(A_k) \]
:::

**Illustration of a Partition**

```{r, echo=F}
plot.new()
box()
```

\vfill

\newpage

:::{.example}
Box \#1 has ten computer chips (five working and five broken). Box \#2 has five (one working and four broken). Suppose we randomly select one of the two boxes and then randomly select a chip. What is the probability that the chip is broken?
:::

\vfill

:::{.theorem}
Bayes' Theorem: Suppose that $A_1 \cap A_2 = \emptyset$ and $A_1 \cup A_2 = \Omega$, then if $P(B)>0$,

\[ P(A_1|B) = \frac{P(B|A_1)P(A_1)}{P(B|A_1)P(A_1)+P(B|A_2)P(A_2)} \]  

\smallskip
    
Let $A_1, A_2, \ldots, A_k$ be a collection of mutually exclusive and exhaustive events, then if $P(B)>0$,

\[P(A_j|B) = \frac{P(A_j \cap B)}{P(B)} = \frac{P(B|A_j) \cdot P(A_j)}{\sum_{i=1}^k P(B|A_i) \cdot P(A_i)}
\]
:::

\smallskip

:::{.example}
Suppose a test to detect a rare disease is positive 95\% of the time for a person with a disease and is positive 1\% of the time for a person without the disease. Further, assume that 0.5\% of the population has the disease. Given that a person tests positive for a disease, what is the probability that they actually has the disease?
:::

\vfill

\newpage


## Independence

Recall: 

:::{.definition}
When $A \cap B = \emptyset$, A and B are said to be ***mutually exclusive (or disjoint)*** events.
:::

:::{.definition}
Two events A and B are ***independent*** if $P(A|B) = P(A)$ and ***dependent*** otherwise.

Also, A and B are independent if and only if \(P(A \cap B) = P(A) \cdot P(B)\).
:::

:::{.example}
Recall from the previous example that a test to detect a rare disease is positive 95\% of the time for a person with a disease and is positive 1\% of the time for a person without the disease. Further, assume that 0.5\% of the population has the disease. Let $D$ be the event that one has the disease and let $P$ be the event that one has a positive test.
:::

(a) Are D and P mutually exclusive?
\vfill

(b) Are D and P independent?
\vfill


## Objective vs. Subjective Probability

There are two different interpretations of Probability. Both follow the Axioms of Probability.

:::{.definition}
***Objective Probability*** refers to the probability of an event as determined by the long-term frequency of its occurrence, based on repeated trials or observations. It is rooted in empirical data and reflects the likelihood of an event as the proportion of times it occurs in a large number of trials.
:::

:::{.example}
I flip a coin 100 times and it lands on head 53 times. I estimate the probability of flipping a heads to be $P_{100}(head) = \frac{53}{100} = 0.53$. As we flip the coin more and more, we would expect that $P_n(head) \to 0.5$ as $n \to \infty$ if the coin is actually a fair coin.
:::

:::{.definition}
***Subjective Probability*** refers to the probability of an event as determined by an individual's personal judgment or belief, rather than objective data. It reflects the degree of confidence one has in the occurrence of an event. A well-known approach to subjective probability is Bayesian probability, which updates these beliefs based on new evidence.
:::

:::{.example}
I am given a coin which I have no reason to believe it is unfair (i.e, $P(head) = 0.5$). I flip the coin 100 times and 3 land on heads. Since this is very unlikely to happen if the coin is fair, I update my estimate to be $P(head)=0.1$ (i.e., somewhere in between $3/100=0.03$ and $1/2 = 0.5$).
:::

\newpage

## R Companion for Chapter 2

:::{.example}
Let's simulate a fair six-sided die roll. Recall that we need to use the \textbf{set.seed} function so that we all generate the same random data. For consistency, I always set the seed to 2020, i.e., set.seed(2020). The sample function will generate 100 random die rolls with each possible outcome (1,2,3,4,5,6) being equally likely.
:::

```{r}
set.seed(2020)
data = sample(x = 1:6,size = 100,replace = T); data
```

Let's make a histogram of the simulated data. Recall that each outcome (1,2,3,4,5,6) is equally likely in theory but in our simulation, some numbers may come up more than others. To make the histogram look better, I define the boundary breaks to be 0:6 (i.e., 0,1,2,3,4,5,6). 

```{r}
hist(data,breaks=0:6)
```

With only 100 random die rolls, the distribution isn't as flat, uniform, and symmetric as we would expect. The number 3 came up less than we would anticipate. This is OK. 

\newpage

We can also generate a frequency table and use this to create a barplot. This looks a little nicer than the standard histogram and doesn't require use to use the \textbf{breaks} argument.

```{r}
table(data)
barplot(table(data))
```

If we want a better representation of the true distribution of the fair six-sided die rolls, we could simulate 10000 die rolls instead of 100.

```{r}
set.seed(2020)
data = sample(x = 1:6,size = 10000,replace = T)
table(data)
```

\newpage

```{r,out.width="75%"}
barplot(table(data))
```

Simulation can be helpful for us to verify hand calculations and to estimate quantities that are hard to calculate by hand. Our simulation results won't exactly match our hand calculations, but if the sample size is large enough, they should be close.\\

For instance, we know that P(Roll=1) = 1/6 for the population of all fair six-sided die rolls. If you refer to the table at the bottom of the previous page, you see that 1 came up 1630 times out of 10000 die rolls. In the simulation, P(1) = 1630/10000 = 0.1630 which is pretty close the the theoretical value of P(1) = 1/6 = 0.1667.\\

Here is an example of how to calculate the probability of a die roll less than 3 in our simulation.

```{r}
# Calculate P(Roll < 3)
# From theory, we know that P(Roll < 3) = P(1) + P(2) = 1/6 + 1/6 = 1/3

# count up the number of rolls less than 3
num.under3 = sum( data < 3 ) 

# divide the number of rolls less than 3 by the number of rolls
prob.under3 = num.under3 / 10000
prob.under3

# alternatively:
prob.under3 = mean(data < 3)
prob.under3
```

From theory, we expect P(Roll $<$ 3) = 1/3 = 0.3333. In our simulation, we found P(Roll $<$ 3) = 0.3287.

\newpage

:::{.example}
Let's simulate rolling two fair six-sided dice 10,000 times and calculate some probabilities. \textbf{d1} will represent the first die roll and \textbf{d2} will represent the second die roll.
:::

```{r}
set.seed(2020)
d1 = sample(x = 1:6,size = 10000,replace = T)
d2 = sample(x = 1:6,size = 10000,replace = T)
```

From our simulated data, let's calculate P(D1 = 1 and D2 = 2), that is, the probability that first die roll is 1 and the second die roll is 2. From theory, this probability should be 1/36 = 0.0278. (We use the \textbf{\&} for \textbf{AND} in R.)

```{r}
num.events = sum(d1 == 1 & d2 == 2)
prob = num.events / 10000; prob
```

Next, let's calculate P(D1 $<$ 2 or D2 $>$ 2), that is, the probability that the first die roll is less than 2 or the second die roll is greater than 2. From theory, this probability should be 0.7222. We use the \textbf{$\vert$} for the \textbf{OR} in R.)

```{r}
num.events = sum(d1 < 2 | d2 > 2)
prob = num.events / 10000; prob
```

Finally, let's look at the frequency table and distribution of the sum of the two die rolls.

```{r,out.width="70%"}
table(d1+d2)
barplot(table(d1+d2),xlab="Sum of Dice",ylab="Counts")
```

